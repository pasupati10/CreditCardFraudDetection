{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection\n",
    "\n",
    "In this project you will predict fraudulent credit card transactions with the help of Machine learning models. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(r'D:\\upgrad\\ML_Practice\\CreditcardFaurd\\creditcard.csv')\n",
    "df = pd.read_csv(r'creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#observe the different feature type present in the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will observe the distribution of our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "99.82725143693798\n",
      "0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "classes=df['Class'].value_counts()\n",
    "print(classes)\n",
    "normal_share=classes[0]/df['Class'].count()*100\n",
    "fraud_share=classes[1]/df['Class'].count()*100\n",
    "print(normal_share)\n",
    "print(fraud_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.2, 0.5, '99.83%')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "plt.bar(['Non-Fraud','Fraud'],classes)\n",
    "plt.ylabel(\"Number of Transaction\")\n",
    "plt.annotate(\"{0:.4}%\".format(fraud_share),(0.7, 0.5), xycoords='axes fraction')\n",
    "plt.annotate(\"{0:.4}%\".format(normal_share),(0.2, 0.5), xycoords='axes fraction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              0.0\n",
      "1              0.0\n",
      "2              1.0\n",
      "3              1.0\n",
      "4              2.0\n",
      "            ...   \n",
      "284802    172786.0\n",
      "284803    172787.0\n",
      "284804    172788.0\n",
      "284805    172788.0\n",
      "284806    172792.0\n",
      "Name: Time, Length: 284807, dtype: float64\n",
      "0          0.000000\n",
      "1          0.000000\n",
      "2          0.000278\n",
      "3          0.000278\n",
      "4          0.000556\n",
      "            ...    \n",
      "284802    47.996111\n",
      "284803    47.996389\n",
      "284804    47.996667\n",
      "284805    47.996667\n",
      "284806    47.997778\n",
      "Name: Time, Length: 284807, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with time\n",
    "plt.scatter(df.Time,df.Class)\n",
    "print(df.Time)\n",
    "print(df.Time/(60*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Class')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with Amount\n",
    "plt.scatter(df.Amount,df.Class)\n",
    "plt.xlabel(\"Amount\")\n",
    "plt.ylabel(\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(['Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df.Class\n",
    "df.drop('Class',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preserve X_test & y_test to evaluate on the test data once you build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "375\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y))\n",
    "print(np.sum(y_train))\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the distribution of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  0., ..., 33.,  5.,  4.]),\n",
       " array([-46.8550472 , -46.83196201, -46.80887681, ...,   2.4087596 ,\n",
       "          2.4318448 ,   2.45492999]),\n",
       " <a list of 2136 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogram of a variable from the dataset to see the skewness\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(X_train.iloc[:,0], bins=int(X_train.shape[0]/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282280   -0.463674\n",
       "84566    -2.050232\n",
       "267945   -2.910537\n",
       "1109     -0.443986\n",
       "234206   -1.084160\n",
       "            ...   \n",
       "32384    -0.520184\n",
       "49597     1.432626\n",
       "219404    1.905719\n",
       "13638     1.221701\n",
       "191595    1.449959\n",
       "Name: V1, Length: 213605, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there is skewness present in the distribution use:\n",
    "- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7098621 ,  0.33742381, -0.56078477, ...,  0.18782822,\n",
       "        -0.14284714,  0.76895197],\n",
       "       [-1.01825147,  0.03070744, -0.15051793, ..., -0.35960824,\n",
       "         0.06840878,  1.48227612],\n",
       "       [ 1.66579877, -0.8712172 , -0.77557483, ...,  0.00223718,\n",
       "        -0.16543974, -0.42851857],\n",
       "       ...,\n",
       "       [ 0.61323429,  0.03653191,  0.14325933, ...,  0.07867813,\n",
       "         0.0502764 , -1.26560978],\n",
       "       [ 1.25765008, -0.36967428, -0.23777954, ...,  0.14155275,\n",
       "        -0.02745715,  0.43988794],\n",
       "       [ 0.12803339, -0.89828476,  0.56897286, ..., -0.20356839,\n",
       "         0.20866813,  1.5057891 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\n",
    "from sklearn import preprocessing\n",
    "powerTransformer=preprocessing.PowerTransformer(copy=False)\n",
    "powerTransformer.fit_transform(X_train)\n",
    "powerTransformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., ..., 1., 0., 2.]),\n",
       " array([-7.65881167, -7.65435185, -7.64989203, ...,  1.85844905,\n",
       "         1.86290887,  1.86736869]),\n",
       " <a list of 2136 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogram of a variable from the dataset again to see the result \n",
    "plt.hist(X_train.iloc[:,0], bins=int(X_train.shape[0]/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Build different models on the imbalanced dataset and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "num_split=3\n",
    "skf=model_selection.StratifiedKFold(n_splits=num_split,shuffle=True,random_state=0)\n",
    "from sklearn import linear_model #import the package\n",
    "\n",
    "num_C = [0.001,.01,.1,1.0,10.0,100.0,1000.0]  \n",
    "cv_num = 0\n",
    "auc=np.zeros((len(num_C),num_split))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perfom cross validation on the X_train & y_train to create:\n",
    "- X_train_cv\n",
    "- X_test_cv \n",
    "- y_train_cv\n",
    "- y_test_cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_val = 0.001 ; auc = 0.9888753886629993 ; cv_num = 0\n",
      "C_val = 0.01 ; auc = 0.9912336198770348 ; cv_num = 0\n",
      "C_val = 0.1 ; auc = 0.987310663083698 ; cv_num = 0\n",
      "C_val = 1.0 ; auc = 0.9856450891286914 ; cv_num = 0\n",
      "C_val = 10.0 ; auc = 0.985428535250503 ; cv_num = 0\n",
      "C_val = 100.0 ; auc = 0.98540534912841 ; cv_num = 0\n",
      "C_val = 1000.0 ; auc = 0.985403210602586 ; cv_num = 0\n",
      "C_val = 0.001 ; auc = 0.983754857408163 ; cv_num = 1\n",
      "C_val = 0.01 ; auc = 0.9804260731319554 ; cv_num = 1\n",
      "C_val = 0.1 ; auc = 0.9790688971115831 ; cv_num = 1\n",
      "C_val = 1.0 ; auc = 0.978361495279767 ; cv_num = 1\n",
      "C_val = 10.0 ; auc = 0.9782704391012563 ; cv_num = 1\n",
      "C_val = 100.0 ; auc = 0.9782554694204877 ; cv_num = 1\n",
      "C_val = 1000.0 ; auc = 0.978255694528469 ; cv_num = 1\n",
      "C_val = 0.001 ; auc = 0.9582809387134897 ; cv_num = 2\n",
      "C_val = 0.01 ; auc = 0.9647880015757782 ; cv_num = 2\n",
      "C_val = 0.1 ; auc = 0.9685285609769825 ; cv_num = 2\n",
      "C_val = 1.0 ; auc = 0.9691056334064946 ; cv_num = 2\n",
      "C_val = 10.0 ; auc = 0.9691726039732117 ; cv_num = 2\n",
      "C_val = 100.0 ; auc = 0.969175530418144 ; cv_num = 2\n",
      "C_val = 1000.0 ; auc = 0.9691758680848668 ; cv_num = 2\n",
      "[[0.98887539 0.98375486 0.95828094]\n",
      " [0.99123362 0.98042607 0.964788  ]\n",
      " [0.98731066 0.9790689  0.96852856]\n",
      " [0.98564509 0.9783615  0.96910563]\n",
      " [0.98542854 0.97827044 0.9691726 ]\n",
      " [0.98540535 0.97825547 0.96917553]\n",
      " [0.98540321 0.97825569 0.96917587]]\n",
      "Best C: 0.01\n",
      "Best auc corresponding to Best C: 0.9788158981949229\n"
     ]
    }
   ],
   "source": [
    "#perform cross validation with Logistic Regression\n",
    "cv_num=0\n",
    "for trainindex,testindex in skf.split(X_train,y_train):\n",
    "    xtraincv,xtestcv=X_train.iloc[trainindex],X_train.iloc[testindex]\n",
    "    ytraincv,ytestcv=y_train.iloc[trainindex],y_train.iloc[testindex]\n",
    "    for id,val in enumerate(num_C):\n",
    "        lr=linear_model.LogisticRegression(C=val, random_state=0, solver='lbfgs', max_iter=1000, n_jobs=-1)\n",
    "        lr.fit(xtraincv,ytraincv)\n",
    "        score=lr.predict_proba(xtestcv)        \n",
    "        auc[id,cv_num]=metrics.roc_auc_score(y_true=ytestcv,y_score=score[:,1])\n",
    "        print('C_val =', val, '; auc =', auc[id, cv_num], '; cv_num =', cv_num)\n",
    "    cv_num=cv_num+1\n",
    "\n",
    "print(auc)\n",
    "mean_auc = np.mean(auc, axis=1)\n",
    "print('Best C:', num_C[np.argmax(mean_auc)])\n",
    "print('Best auc corresponding to Best C:', mean_auc[np.argmax(mean_auc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 2 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9357416323142508 ; cv_num = 0\n",
      "depth = 2 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9357416323142508 ; cv_num = 0\n",
      "depth = 2 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9357329093799681 ; cv_num = 0\n",
      "depth = 2 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9357329093799681 ; cv_num = 0\n",
      "depth = 2 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9396889570465833 ; cv_num = 0\n",
      "depth = 2 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9396889570465833 ; cv_num = 0\n",
      "depth = 3 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9442374889204664 ; cv_num = 0\n",
      "depth = 3 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9442374889204664 ; cv_num = 0\n",
      "depth = 3 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9442098569157392 ; cv_num = 0\n",
      "depth = 3 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9442098569157392 ; cv_num = 0\n",
      "depth = 3 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9531202498698594 ; cv_num = 0\n",
      "depth = 3 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9531202498698594 ; cv_num = 0\n",
      "depth = 4 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9456425003869043 ; cv_num = 0\n",
      "depth = 4 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9456425003869043 ; cv_num = 0\n",
      "depth = 4 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.945614868382177 ; cv_num = 0\n",
      "depth = 4 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.945614868382177 ; cv_num = 0\n",
      "depth = 4 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.954564036186108 ; cv_num = 0\n",
      "depth = 4 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.954564036186108 ; cv_num = 0\n",
      "depth = 5 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9498004699129113 ; cv_num = 0\n",
      "depth = 5 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9498004699129113 ; cv_num = 0\n",
      "depth = 5 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9497664786077071 ; cv_num = 0\n",
      "depth = 5 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9497664786077071 ; cv_num = 0\n",
      "depth = 5 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9578309157674072 ; cv_num = 0\n",
      "depth = 5 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9578309157674072 ; cv_num = 0\n",
      "depth = 6 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9417520716968921 ; cv_num = 0\n",
      "depth = 6 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9417520716968921 ; cv_num = 0\n",
      "depth = 6 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9417254526780815 ; cv_num = 0\n",
      "depth = 6 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9417254526780815 ; cv_num = 0\n",
      "depth = 6 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9476581172531199 ; cv_num = 0\n",
      "depth = 6 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9476581172531199 ; cv_num = 0\n",
      "depth = 2 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9317210912109403 ; cv_num = 1\n",
      "depth = 2 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9317210912109403 ; cv_num = 1\n",
      "depth = 2 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.93170893537994 ; cv_num = 1\n",
      "depth = 2 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.93170893537994 ; cv_num = 1\n",
      "depth = 2 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9317054462062271 ; cv_num = 1\n",
      "depth = 2 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9317054462062271 ; cv_num = 1\n",
      "depth = 3 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9366919819350844 ; cv_num = 1\n",
      "depth = 3 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9366919819350844 ; cv_num = 1\n",
      "depth = 3 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9366458910758755 ; cv_num = 1\n",
      "depth = 3 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9366458910758755 ; cv_num = 1\n",
      "depth = 3 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9365710989490271 ; cv_num = 1\n",
      "depth = 3 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9365710989490271 ; cv_num = 1\n",
      "depth = 4 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9676451735441844 ; cv_num = 1\n",
      "depth = 4 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9676451735441844 ; cv_num = 1\n",
      "depth = 4 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9675054377646778 ; cv_num = 1\n",
      "depth = 4 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9675054377646778 ; cv_num = 1\n",
      "depth = 4 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9674563079477186 ; cv_num = 1\n",
      "depth = 4 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9674563079477186 ; cv_num = 1\n",
      "depth = 5 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9725124020428549 ; cv_num = 1\n",
      "depth = 5 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9725124020428549 ; cv_num = 1\n",
      "depth = 5 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9750976546562178 ; cv_num = 1\n",
      "depth = 5 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9750976546562178 ; cv_num = 1\n",
      "depth = 5 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9751477974590936 ; cv_num = 1\n",
      "depth = 5 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9751477974590936 ; cv_num = 1\n",
      "depth = 6 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9450905918932988 ; cv_num = 1\n",
      "depth = 6 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9450905918932988 ; cv_num = 1\n",
      "depth = 6 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.968401142423006 ; cv_num = 1\n",
      "depth = 6 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.968401142423006 ; cv_num = 1\n",
      "depth = 6 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9691214316867622 ; cv_num = 1\n",
      "depth = 6 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9691214316867622 ; cv_num = 1\n",
      "depth = 2 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9116796668355001 ; cv_num = 2\n",
      "depth = 2 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9116796668355001 ; cv_num = 2\n",
      "depth = 2 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9116675671112612 ; cv_num = 2\n",
      "depth = 2 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9116675671112612 ; cv_num = 2\n",
      "depth = 2 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9116812426135404 ; cv_num = 2\n",
      "depth = 2 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9116812426135404 ; cv_num = 2\n",
      "depth = 3 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9220773256795541 ; cv_num = 2\n",
      "depth = 3 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9220773256795541 ; cv_num = 2\n",
      "depth = 3 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9220598232877482 ; cv_num = 2\n",
      "depth = 3 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9220598232877482 ; cv_num = 2\n",
      "depth = 3 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.921993584332264 ; cv_num = 2\n",
      "depth = 3 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.921993584332264 ; cv_num = 2\n",
      "depth = 4 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9307099442849907 ; cv_num = 2\n",
      "depth = 4 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9307099442849907 ; cv_num = 2\n",
      "depth = 4 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9305936180989363 ; cv_num = 2\n",
      "depth = 4 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9305936180989363 ; cv_num = 2\n",
      "depth = 4 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.930527379143452 ; cv_num = 2\n",
      "depth = 4 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.930527379143452 ; cv_num = 2\n",
      "depth = 5 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9144698632449771 ; cv_num = 2\n",
      "depth = 5 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9144698632449771 ; cv_num = 2\n",
      "depth = 5 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9299162023749226 ; cv_num = 2\n",
      "depth = 5 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9299162023749226 ; cv_num = 2\n",
      "depth = 5 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9348192920254375 ; cv_num = 2\n",
      "depth = 5 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9348192920254375 ; cv_num = 2\n",
      "depth = 6 ; min_samples_leaf = 30 ; min_samples_split = 2 ; auc = 0.9417178794529799 ; cv_num = 2\n",
      "depth = 6 ; min_samples_leaf = 30 ; min_samples_split = 31 ; auc = 0.9417178794529799 ; cv_num = 2\n",
      "depth = 6 ; min_samples_leaf = 50 ; min_samples_split = 2 ; auc = 0.9506308739940345 ; cv_num = 2\n",
      "depth = 6 ; min_samples_leaf = 50 ; min_samples_split = 31 ; auc = 0.9506308739940345 ; cv_num = 2\n",
      "depth = 6 ; min_samples_leaf = 100 ; min_samples_split = 2 ; auc = 0.9358214305813495 ; cv_num = 2\n",
      "depth = 6 ; min_samples_leaf = 100 ; min_samples_split = 31 ; auc = 0.9358214305813495 ; cv_num = 2\n",
      "Best depth: 5\n",
      "Best min_samples_leaf: 100\n",
      "Best min_samples_split: 30\n",
      "Best auc corresponding to Best depth, min_samples_leaf & min_samples_split : 0.9559326684173127\n"
     ]
    }
   ],
   "source": [
    "# perform cross validation with decision tree\n",
    "from sklearn import tree\n",
    "num_cv_splits=3\n",
    "num_depth = range(2, 7)\n",
    "num_min_samples_leaf = [30,50,100]\n",
    "num_min_samples_split = [2,31]\n",
    "auc = np.zeros((len(num_depth)*len(num_min_samples_leaf)*len(num_min_samples_split), num_cv_splits))\n",
    "cv_num = 0\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    for depth_id, depth in enumerate(num_depth):\n",
    "        for min_samples_leaf_id, min_samples_leaf in enumerate(num_min_samples_leaf):\n",
    "            for min_samples_split_id, min_samples_split in enumerate(num_min_samples_split):\n",
    "                clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=depth,\n",
    "                        min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, random_state=0)\n",
    "                clf.fit(X_train_cv, y_train_cv)\n",
    "                auc_id = depth_id*len(num_min_samples_leaf)*len(num_min_samples_split)+\\\n",
    "                            min_samples_leaf_id*len(num_min_samples_split)+min_samples_split_id\n",
    "                auc[auc_id, cv_num] = metrics.roc_auc_score(y_true = y_test_cv, y_score = clf.predict_proba(X_test_cv)[:,1])\n",
    "                print('depth =', depth, '; min_samples_leaf =', min_samples_leaf, '; min_samples_split =',\n",
    "                      min_samples_split, '; auc =', auc[auc_id, cv_num], '; cv_num =', cv_num)\n",
    "    cv_num += 1\n",
    "mean_auc = np.mean(auc, axis=1)\n",
    "depth_id = np.argmax(mean_auc)//(len(num_min_samples_leaf)*len(num_min_samples_split))\n",
    "min_samples_leaf_id = (np.argmax(mean_auc) - depth_id*len(num_min_samples_leaf)*len(num_min_samples_split))//len(\n",
    "                       num_min_samples_split)\n",
    "min_samples_split_id = (np.argmax(mean_auc) - depth_id*len(num_min_samples_leaf)*len(num_min_samples_split))%len(\n",
    "                       num_min_samples_split)\n",
    "print('Best depth:', num_depth[depth_id])\n",
    "print('Best min_samples_leaf:', num_min_samples_leaf[min_samples_leaf_id])\n",
    "print('Best min_samples_split:', num_min_samples_leaf[min_samples_split_id])\n",
    "print('Best auc corresponding to Best depth, min_samples_leaf & min_samples_split :', mean_auc[np.argmax(mean_auc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees = 801 ; auc = 0.9696211714056587 ; cv_num = 0\n",
      "num_trees = 802 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 803 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 804 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 805 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 806 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 807 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 808 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 809 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 810 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 811 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 812 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 813 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 814 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 815 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 816 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 817 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 818 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 819 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 820 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 821 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 822 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 823 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 824 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 825 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 826 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 827 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 828 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 829 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 830 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 831 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 832 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 833 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 834 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 835 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 836 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 837 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 838 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 839 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 840 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 841 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 842 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 843 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 844 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 845 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 846 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 847 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 848 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 849 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 850 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 851 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 852 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 853 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 854 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 855 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 856 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 857 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 858 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 859 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 860 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 861 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 862 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 863 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 864 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 865 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 866 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 867 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 868 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 869 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 870 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 871 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 872 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 873 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 874 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 875 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 876 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 877 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 878 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 879 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 880 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 881 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 882 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 883 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 884 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 885 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 886 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 887 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 888 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 889 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 890 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 891 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 892 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 893 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 894 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 895 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 896 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 897 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 898 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 899 ; auc = 0.0 ; cv_num = 0\n",
      "num_trees = 801 ; auc = 0.984620510150963 ; cv_num = 1\n",
      "num_trees = 802 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 803 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 804 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 805 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 806 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 807 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 808 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 809 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 810 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 811 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 812 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 813 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 814 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 815 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 816 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 817 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 818 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 819 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 820 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 821 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 822 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 823 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 824 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 825 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 826 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 827 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 828 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 829 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 830 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 831 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 832 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 833 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 834 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 835 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 836 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 837 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 838 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 839 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 840 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 841 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 842 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 843 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 844 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 845 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 846 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 847 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 848 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 849 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 850 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 851 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 852 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 853 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 854 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 855 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 856 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 857 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 858 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 859 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 860 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 861 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 862 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 863 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 864 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 865 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 866 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 867 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 868 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 869 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 870 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 871 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 872 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 873 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 874 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 875 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 876 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 877 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 878 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 879 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 880 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 881 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 882 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 883 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 884 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 885 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 886 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 887 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 888 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 889 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 890 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 891 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 892 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 893 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 894 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 895 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 896 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 897 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 898 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 899 ; auc = 0.0 ; cv_num = 1\n",
      "num_trees = 801 ; auc = 0.9747517024030614 ; cv_num = 2\n",
      "num_trees = 802 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 803 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 804 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 805 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 806 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 807 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 808 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 809 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 810 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 811 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 812 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 813 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 814 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 815 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 816 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 817 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 818 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 819 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 820 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 821 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 822 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 823 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 824 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 825 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 826 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 827 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 828 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 829 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 830 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 831 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 832 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 833 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 834 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 835 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 836 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 837 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 838 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 839 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 840 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 841 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 842 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 843 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 844 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 845 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 846 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 847 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 848 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 849 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 850 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 851 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 852 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 853 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 854 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 855 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 856 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 857 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 858 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 859 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 860 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 861 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 862 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 863 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 864 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 865 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 866 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 867 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 868 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 869 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 870 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 871 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 872 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 873 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 874 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 875 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 876 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 877 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 878 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 879 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 880 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 881 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 882 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 883 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 884 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 885 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 886 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 887 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 888 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 889 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 890 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 891 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 892 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 893 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 894 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 895 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 896 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 897 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 898 ; auc = 0.0 ; cv_num = 2\n",
      "num_trees = 899 ; auc = 0.0 ; cv_num = 2\n"
     ]
    }
   ],
   "source": [
    "num_cv_splits=3\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "intial_trees=801\n",
    "num_trees=899\n",
    "tree_increment=1\n",
    "trees=range(intial_trees,num_trees+1,tree_increment)\n",
    "auc=np.zeros((len(trees),num_cv_splits))\n",
    "cv_num=0\n",
    "for train_index,test_index in skf.split(X_train,y_train):\n",
    "    xtrain_cv,xtest_cv=X_train.iloc[train_index],X_train.iloc[test_index]\n",
    "    ytrain_cv,ytest_cv=y_train.iloc[train_index],y_train.iloc[test_index]\n",
    "    clf=ensemble.RandomForestClassifier(criterion='entropy',min_samples_leaf=30,warm_start=True,n_jobs=-1,random_state=0)\n",
    "    for tree_id,tree in enumerate(trees):\n",
    "        clf.set_params(n_estimators=tree)\n",
    "        clf.fit(xtrain_cv,ytrain_cv)\n",
    "        auc[id,cv_num]=metrics.roc_auc_score(y_true=ytest_cv,y_score=clf.predict_proba(xtest_cv)[:,1])\n",
    "        print('num_trees =', tree, '; auc =', auc[tree_id, cv_num], '; cv_num =', cv_num)\n",
    "    cv_num=cv_num+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best num_trees: 801\n",
      "Best auc corresponding to Best num_trees : 0.9776175656543614\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.mean(auc, axis=1)\n",
    "print('Best num_trees:', trees[np.argmax(mean_auc)])\n",
    "print('Best auc corresponding to Best num_trees :', mean_auc[np.argmax(mean_auc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees = 801 ; auc = 0.9712640094545352 ; cv_num = 0\n",
      "num_trees = 802 ; auc = 0.9712558492902066 ; cv_num = 0\n",
      "num_trees = 803 ; auc = 0.9712495462667248 ; cv_num = 0\n",
      "num_trees = 804 ; auc = 0.9712423990883126 ; cv_num = 0\n",
      "num_trees = 805 ; auc = 0.9712308060272663 ; cv_num = 0\n",
      "num_trees = 806 ; auc = 0.9712211263840623 ; cv_num = 0\n",
      "num_trees = 807 ; auc = 0.9711995160178396 ; cv_num = 0\n",
      "num_trees = 808 ; auc = 0.9711923125624322 ; cv_num = 0\n",
      "num_trees = 809 ; auc = 0.9711831956891821 ; cv_num = 0\n",
      "num_trees = 810 ; auc = 0.9711767801117097 ; cv_num = 0\n",
      "num_trees = 811 ; auc = 0.9711678883464412 ; cv_num = 0\n",
      "num_trees = 812 ; auc = 0.9711573645483067 ; cv_num = 0\n",
      "num_trees = 813 ; auc = 0.9711545506985382 ; cv_num = 0\n",
      "num_trees = 814 ; auc = 0.9711377238769221 ; cv_num = 0\n",
      "num_trees = 815 ; auc = 0.971131927346399 ; cv_num = 0\n",
      "num_trees = 816 ; auc = 0.9711252303839495 ; cv_num = 0\n",
      "num_trees = 817 ; auc = 0.97111768926657 ; cv_num = 0\n",
      "num_trees = 818 ; auc = 0.9711077845153848 ; cv_num = 0\n",
      "num_trees = 819 ; auc = 0.9710964165623197 ; cv_num = 0\n",
      "num_trees = 820 ; auc = 0.9710856113792085 ; cv_num = 0\n",
      "num_trees = 821 ; auc = 0.9710798148486851 ; cv_num = 0\n",
      "num_trees = 822 ; auc = 0.9710721611773148 ; cv_num = 0\n",
      "num_trees = 823 ; auc = 0.971065970707824 ; cv_num = 0\n",
      "num_trees = 824 ; auc = 0.9710582607594579 ; cv_num = 0\n",
      "num_trees = 825 ; auc = 0.9710477369613235 ; cv_num = 0\n",
      "num_trees = 826 ; auc = 0.9710337802664715 ; cv_num = 0\n",
      "num_trees = 827 ; auc = 0.9710273084120038 ; cv_num = 0\n",
      "num_trees = 828 ; auc = 0.9710217932664573 ; cv_num = 0\n",
      "num_trees = 829 ; auc = 0.9710201049565963 ; cv_num = 0\n",
      "num_trees = 830 ; auc = 0.97100400973592 ; cv_num = 0\n",
      "num_trees = 831 ; auc = 0.9709995075762905 ; cv_num = 0\n",
      "num_trees = 832 ; auc = 0.9709852132194661 ; cv_num = 0\n",
      "num_trees = 833 ; auc = 0.9709776721020864 ; cv_num = 0\n",
      "num_trees = 834 ; auc = 0.9709648409471419 ; cv_num = 0\n",
      "num_trees = 835 ; auc = 0.9709574686607481 ; cv_num = 0\n",
      "num_trees = 836 ; auc = 0.9709484080644935 ; cv_num = 0\n",
      "num_trees = 837 ; auc = 0.9709440747358498 ; cv_num = 0\n",
      "num_trees = 838 ; auc = 0.97107221745431 ; cv_num = 0\n",
      "num_trees = 839 ; auc = 0.9710679404026618 ; cv_num = 0\n",
      "num_trees = 840 ; auc = 0.9710587672524164 ; cv_num = 0\n",
      "num_trees = 841 ; auc = 0.9710511135810459 ; cv_num = 0\n",
      "num_trees = 842 ; auc = 0.9710395205199993 ; cv_num = 0\n",
      "num_trees = 843 ; auc = 0.9710353560223419 ; cv_num = 0\n",
      "num_trees = 844 ; auc = 0.9710241569002632 ; cv_num = 0\n",
      "num_trees = 845 ; auc = 0.9710078365716053 ; cv_num = 0\n",
      "num_trees = 846 ; auc = 0.970994442646707 ; cv_num = 0\n",
      "num_trees = 847 ; auc = 0.9709889837781562 ; cv_num = 0\n",
      "num_trees = 848 ; auc = 0.9709787976419939 ; cv_num = 0\n",
      "num_trees = 849 ; auc = 0.9709728322804847 ; cv_num = 0\n",
      "num_trees = 850 ; auc = 0.9709616331584057 ; cv_num = 0\n",
      "num_trees = 851 ; auc = 0.9709449751677759 ; cv_num = 0\n",
      "num_trees = 852 ; auc = 0.9709371526654191 ; cv_num = 0\n",
      "num_trees = 853 ; auc = 0.9709273604682246 ; cv_num = 0\n",
      "num_trees = 854 ; auc = 0.9710738494871759 ; cv_num = 0\n",
      "num_trees = 855 ; auc = 0.9710672650787173 ; cv_num = 0\n",
      "num_trees = 856 ; auc = 0.9710587672524165 ; cv_num = 0\n",
      "num_trees = 857 ; auc = 0.971055840848657 ; cv_num = 0\n",
      "num_trees = 858 ; auc = 0.9710446417265781 ; cv_num = 0\n",
      "num_trees = 859 ; auc = 0.9710324296185828 ; cv_num = 0\n",
      "num_trees = 860 ; auc = 0.9710230313603557 ; cv_num = 0\n",
      "num_trees = 861 ; auc = 0.9710105941443786 ; cv_num = 0\n",
      "num_trees = 862 ; auc = 0.9710050227218369 ; cv_num = 0\n",
      "num_trees = 863 ; auc = 0.9709972564964757 ; cv_num = 0\n",
      "num_trees = 864 ; auc = 0.9709893214401284 ; cv_num = 0\n",
      "num_trees = 865 ; auc = 0.9709871266373089 ; cv_num = 0\n",
      "num_trees = 866 ; auc = 0.9709786288110077 ; cv_num = 0\n",
      "num_trees = 867 ; auc = 0.9709713128016095 ; cv_num = 0\n",
      "num_trees = 868 ; auc = 0.9709646721161558 ; cv_num = 0\n",
      "num_trees = 869 ; auc = 0.9709594946325816 ; cv_num = 0\n",
      "num_trees = 870 ; auc = 0.970952572562151 ; cv_num = 0\n",
      "num_trees = 871 ; auc = 0.9709446375058035 ; cv_num = 0\n",
      "num_trees = 872 ; auc = 0.9709391223602573 ; cv_num = 0\n",
      "num_trees = 873 ; auc = 0.9709286548391182 ; cv_num = 0\n",
      "num_trees = 874 ; auc = 0.9709226894776088 ; cv_num = 0\n",
      "num_trees = 875 ; auc = 0.9709152609142199 ; cv_num = 0\n",
      "num_trees = 876 ; auc = 0.9709077197968401 ; cv_num = 0\n",
      "num_trees = 877 ; auc = 0.9708954514118491 ; cv_num = 0\n",
      "num_trees = 878 ; auc = 0.9708880791254555 ; cv_num = 0\n",
      "num_trees = 879 ; auc = 0.9708805942850711 ; cv_num = 0\n",
      "num_trees = 880 ; auc = 0.9708777804353025 ; cv_num = 0\n",
      "num_trees = 881 ; auc = 0.9708728280597099 ; cv_num = 0\n",
      "num_trees = 882 ; auc = 0.970862529369557 ; cv_num = 0\n",
      "num_trees = 883 ; auc = 0.9708557761301124 ; cv_num = 0\n",
      "num_trees = 884 ; auc = 0.9708468843648438 ; cv_num = 0\n",
      "num_trees = 885 ; auc = 0.9708432263601446 ; cv_num = 0\n",
      "num_trees = 886 ; auc = 0.9708269060314869 ; cv_num = 0\n",
      "num_trees = 887 ; auc = 0.9708231354727971 ; cv_num = 0\n",
      "num_trees = 888 ; auc = 0.970827074862473 ; cv_num = 0\n",
      "num_trees = 889 ; auc = 0.9708218411019036 ; cv_num = 0\n",
      "num_trees = 890 ; auc = 0.970817057557297 ; cv_num = 0\n",
      "num_trees = 891 ; auc = 0.9708101917638617 ; cv_num = 0\n",
      "num_trees = 892 ; auc = 0.9708052956652644 ; cv_num = 0\n",
      "num_trees = 893 ; auc = 0.9707986549798107 ; cv_num = 0\n",
      "num_trees = 894 ; auc = 0.9707898194915373 ; cv_num = 0\n",
      "num_trees = 895 ; auc = 0.9707764255666389 ; cv_num = 0\n",
      "num_trees = 896 ; auc = 0.9707730489469167 ; cv_num = 0\n",
      "num_trees = 897 ; auc = 0.9707663519844677 ; cv_num = 0\n",
      "num_trees = 898 ; auc = 0.9707602177919721 ; cv_num = 0\n",
      "num_trees = 899 ; auc = 0.9707549840314025 ; cv_num = 0\n",
      "num_trees = 801 ; auc = 0.9862713958101776 ; cv_num = 1\n",
      "num_trees = 802 ; auc = 0.9862646988477284 ; cv_num = 1\n",
      "num_trees = 803 ; auc = 0.9862591837021821 ; cv_num = 1\n",
      "num_trees = 804 ; auc = 0.9862512486458348 ; cv_num = 1\n",
      "num_trees = 805 ; auc = 0.9862475343641401 ; cv_num = 1\n",
      "num_trees = 806 ; auc = 0.9862401058007513 ; cv_num = 1\n",
      "num_trees = 807 ; auc = 0.9862296382796122 ; cv_num = 1\n",
      "num_trees = 808 ; auc = 0.9862274997537881 ; cv_num = 1\n",
      "num_trees = 809 ; auc = 0.9862201837443899 ; cv_num = 1\n",
      "num_trees = 810 ; auc = 0.9862141058288897 ; cv_num = 1\n",
      "num_trees = 811 ; auc = 0.9862064521575193 ; cv_num = 1\n",
      "num_trees = 812 ; auc = 0.9863076381951967 ; cv_num = 1\n",
      "num_trees = 813 ; auc = 0.9863005472937799 ; cv_num = 1\n",
      "num_trees = 814 ; auc = 0.986392278796235 ; cv_num = 1\n",
      "num_trees = 815 ; auc = 0.9863808545661747 ; cv_num = 1\n",
      "num_trees = 816 ; auc = 0.9863749454816607 ; cv_num = 1\n",
      "num_trees = 817 ; auc = 0.9863677420262533 ; cv_num = 1\n",
      "num_trees = 818 ; auc = 0.9863613264487808 ; cv_num = 1\n",
      "num_trees = 819 ; auc = 0.9863451186741141 ; cv_num = 1\n",
      "num_trees = 820 ; auc = 0.986334651152975 ; cv_num = 1\n",
      "num_trees = 821 ; auc = 0.9863239585238543 ; cv_num = 1\n",
      "num_trees = 822 ; auc = 0.9863115213078775 ; cv_num = 1\n",
      "num_trees = 823 ; auc = 0.9863062312703126 ; cv_num = 1\n",
      "num_trees = 824 ; auc = 0.9862994217538725 ; cv_num = 1\n",
      "num_trees = 825 ; auc = 0.9863020104956597 ; cv_num = 1\n",
      "num_trees = 826 ; auc = 0.9862959888571547 ; cv_num = 1\n",
      "num_trees = 827 ; auc = 0.9862919931904834 ; cv_num = 1\n",
      "num_trees = 828 ; auc = 0.9862834953641824 ; cv_num = 1\n",
      "num_trees = 829 ; auc = 0.9862838330261547 ; cv_num = 1\n",
      "num_trees = 830 ; auc = 0.986273252951025 ; cv_num = 1\n",
      "num_trees = 831 ; auc = 0.9862614347819969 ; cv_num = 1\n",
      "num_trees = 832 ; auc = 0.9862540062186078 ; cv_num = 1\n",
      "num_trees = 833 ; auc = 0.9862859715519788 ; cv_num = 1\n",
      "num_trees = 834 ; auc = 0.9862795559745066 ; cv_num = 1\n",
      "num_trees = 835 ; auc = 0.9862754477538445 ; cv_num = 1\n",
      "num_trees = 836 ; auc = 0.9862685256834136 ; cv_num = 1\n",
      "num_trees = 837 ; auc = 0.986261434781997 ; cv_num = 1\n",
      "num_trees = 838 ; auc = 0.9862539499416126 ; cv_num = 1\n",
      "num_trees = 839 ; auc = 0.9862432010354967 ; cv_num = 1\n",
      "num_trees = 840 ; auc = 0.9862438763594412 ; cv_num = 1\n",
      "num_trees = 841 ; auc = 0.9862330148993343 ; cv_num = 1\n",
      "num_trees = 842 ; auc = 0.986227949969751 ; cv_num = 1\n",
      "num_trees = 843 ; auc = 0.9862176512795982 ; cv_num = 1\n",
      "num_trees = 844 ; auc = 0.9862121361340519 ; cv_num = 1\n",
      "num_trees = 845 ; auc = 0.9862060582185517 ; cv_num = 1\n",
      "num_trees = 846 ; auc = 0.9861973915612645 ; cv_num = 1\n",
      "num_trees = 847 ; auc = 0.9861865301011579 ; cv_num = 1\n",
      "num_trees = 848 ; auc = 0.9861830409274448 ; cv_num = 1\n",
      "num_trees = 849 ; auc = 0.9861718980823615 ; cv_num = 1\n",
      "num_trees = 850 ; auc = 0.9861651448429168 ; cv_num = 1\n",
      "num_trees = 851 ; auc = 0.9861558591386805 ; cv_num = 1\n",
      "num_trees = 852 ; auc = 0.9861586167114539 ; cv_num = 1\n",
      "num_trees = 853 ; auc = 0.9861520885799908 ; cv_num = 1\n",
      "num_trees = 854 ; auc = 0.9861407206269257 ; cv_num = 1\n",
      "num_trees = 855 ; auc = 0.9861359933593147 ; cv_num = 1\n",
      "num_trees = 856 ; auc = 0.9861237249743235 ; cv_num = 1\n",
      "num_trees = 857 ; auc = 0.9861146081010734 ; cv_num = 1\n",
      "num_trees = 858 ; auc = 0.986109993387453 ; cv_num = 1\n",
      "num_trees = 859 ; auc = 0.9861022834390871 ; cv_num = 1\n",
      "num_trees = 860 ; auc = 0.9860896773921239 ; cv_num = 1\n",
      "num_trees = 861 ; auc = 0.9860781968850684 ; cv_num = 1\n",
      "num_trees = 862 ; auc = 0.9860703181057164 ; cv_num = 1\n",
      "num_trees = 863 ; auc = 0.986055123316966 ; cv_num = 1\n",
      "num_trees = 864 ; auc = 0.9860487077394938 ; cv_num = 1\n",
      "num_trees = 865 ; auc = 0.986041616838077 ; cv_num = 1\n",
      "num_trees = 866 ; auc = 0.9860371146784473 ; cv_num = 1\n",
      "num_trees = 867 ; auc = 0.9860319371948729 ; cv_num = 1\n",
      "num_trees = 868 ; auc = 0.9860908029320314 ; cv_num = 1\n",
      "num_trees = 869 ; auc = 0.986085287786485 ; cv_num = 1\n",
      "num_trees = 870 ; auc = 0.98607769039211 ; cv_num = 1\n",
      "num_trees = 871 ; auc = 0.9860680107489062 ; cv_num = 1\n",
      "num_trees = 872 ; auc = 0.9860632834812948 ; cv_num = 1\n",
      "num_trees = 873 ; auc = 0.9860562488568735 ; cv_num = 1\n",
      "num_trees = 874 ; auc = 0.9860454999507577 ; cv_num = 1\n",
      "num_trees = 875 ; auc = 0.9860371709554426 ; cv_num = 1\n",
      "num_trees = 876 ; auc = 0.9860307553779704 ; cv_num = 1\n",
      "num_trees = 877 ; auc = 0.9860221449976786 ; cv_num = 1\n",
      "num_trees = 878 ; auc = 0.9860194437019008 ; cv_num = 1\n",
      "num_trees = 879 ; auc = 0.9860134783403913 ; cv_num = 1\n",
      "num_trees = 880 ; auc = 0.9860061623309933 ; cv_num = 1\n",
      "num_trees = 881 ; auc = 0.9859948506549236 ; cv_num = 1\n",
      "num_trees = 882 ; auc = 0.9859898982793309 ; cv_num = 1\n",
      "num_trees = 883 ; auc = 0.9859823008849558 ; cv_num = 1\n",
      "num_trees = 884 ; auc = 0.985973690504664 ; cv_num = 1\n",
      "num_trees = 885 ; auc = 0.985962941598548 ; cv_num = 1\n",
      "num_trees = 886 ; auc = 0.9859542186642656 ; cv_num = 1\n",
      "num_trees = 887 ; auc = 0.9859443701900756 ; cv_num = 1\n",
      "num_trees = 888 ; auc = 0.9859357035327884 ; cv_num = 1\n",
      "num_trees = 889 ; auc = 0.985924110471742 ; cv_num = 1\n",
      "num_trees = 890 ; auc = 0.985919720866103 ; cv_num = 1\n",
      "num_trees = 891 ; auc = 0.9859124048567045 ; cv_num = 1\n",
      "num_trees = 892 ; auc = 0.9859064394951953 ; cv_num = 1\n",
      "num_trees = 893 ; auc = 0.9859073399271214 ; cv_num = 1\n",
      "num_trees = 894 ; auc = 0.9859000239177229 ; cv_num = 1\n",
      "num_trees = 895 ; auc = 0.9858969286829776 ; cv_num = 1\n",
      "num_trees = 896 ; auc = 0.9858891624576164 ; cv_num = 1\n",
      "num_trees = 897 ; auc = 0.9858785261054912 ; cv_num = 1\n",
      "num_trees = 898 ; auc = 0.9858698031712085 ; cv_num = 1\n",
      "num_trees = 899 ; auc = 0.9858618118378659 ; cv_num = 1\n",
      "num_trees = 801 ; auc = 0.971815859080421 ; cv_num = 2\n",
      "num_trees = 802 ; auc = 0.9718042658562666 ; cv_num = 2\n",
      "num_trees = 803 ; auc = 0.9717949237435985 ; cv_num = 2\n",
      "num_trees = 804 ; auc = 0.9717888457425855 ; cv_num = 2\n",
      "num_trees = 805 ; auc = 0.9717692610726546 ; cv_num = 2\n",
      "num_trees = 806 ; auc = 0.9717574427373514 ; cv_num = 2\n",
      "num_trees = 807 ; auc = 0.9717420226236705 ; cv_num = 2\n",
      "num_trees = 808 ; auc = 0.9717213686757837 ; cv_num = 2\n",
      "num_trees = 809 ; auc = 0.9716950306713941 ; cv_num = 2\n",
      "num_trees = 810 ; auc = 0.9716745455568688 ; cv_num = 2\n",
      "num_trees = 811 ; auc = 0.9716634025550115 ; cv_num = 2\n",
      "num_trees = 812 ; auc = 0.9716544543868535 ; cv_num = 2\n",
      "num_trees = 813 ; auc = 0.9716462378299285 ; cv_num = 2\n",
      "num_trees = 814 ; auc = 0.9716382463841522 ; cv_num = 2\n",
      "num_trees = 815 ; auc = 0.9716246271596601 ; cv_num = 2\n",
      "num_trees = 816 ; auc = 0.9716089819348304 ; cv_num = 2\n",
      "num_trees = 817 ; auc = 0.9716039169339862 ; cv_num = 2\n",
      "num_trees = 818 ; auc = 0.9715950250436152 ; cv_num = 2\n",
      "num_trees = 819 ; auc = 0.9715882717091562 ; cv_num = 2\n",
      "num_trees = 820 ; auc = 0.9716979008385389 ; cv_num = 2\n",
      "num_trees = 821 ; auc = 0.9716834937250267 ; cv_num = 2\n",
      "num_trees = 822 ; auc = 0.9716645843885416 ; cv_num = 2\n",
      "num_trees = 823 ; auc = 0.9716507400529011 ; cv_num = 2\n",
      "num_trees = 824 ; auc = 0.9716382463841522 ; cv_num = 2\n",
      "num_trees = 825 ; auc = 0.9716439867184423 ; cv_num = 2\n",
      "num_trees = 826 ; auc = 0.9716242894929372 ; cv_num = 2\n",
      "num_trees = 827 ; auc = 0.9716169733806066 ; cv_num = 2\n",
      "num_trees = 828 ; auc = 0.9716042546007092 ; cv_num = 2\n",
      "num_trees = 829 ; auc = 0.9715923237098318 ; cv_num = 2\n",
      "num_trees = 830 ; auc = 0.9717264899544149 ; cv_num = 2\n",
      "num_trees = 831 ; auc = 0.9717134335077944 ; cv_num = 2\n",
      "num_trees = 832 ; auc = 0.9716887275592325 ; cv_num = 2\n",
      "num_trees = 833 ; auc = 0.9716773594462265 ; cv_num = 2\n",
      "num_trees = 834 ; auc = 0.9716693680004502 ; cv_num = 2\n",
      "num_trees = 835 ; auc = 0.9716604761100793 ; cv_num = 2\n",
      "num_trees = 836 ; auc = 0.971712251674264 ; cv_num = 2\n",
      "num_trees = 837 ; auc = 0.9717043727840622 ; cv_num = 2\n",
      "num_trees = 838 ; auc = 0.9716951432269685 ; cv_num = 2\n",
      "num_trees = 839 ; auc = 0.9716860262254488 ; cv_num = 2\n",
      "num_trees = 840 ; auc = 0.9716748832235917 ; cv_num = 2\n",
      "num_trees = 841 ; auc = 0.9716561989982555 ; cv_num = 2\n",
      "num_trees = 842 ; auc = 0.9716493331082221 ; cv_num = 2\n",
      "num_trees = 843 ; auc = 0.9716421295514661 ; cv_num = 2\n",
      "num_trees = 844 ; auc = 0.971626034104339 ; cv_num = 2\n",
      "num_trees = 845 ; auc = 0.9716097135460633 ; cv_num = 2\n",
      "num_trees = 846 ; auc = 0.9715981203219091 ; cv_num = 2\n",
      "num_trees = 847 ; auc = 0.9715875400979234 ; cv_num = 2\n",
      "num_trees = 848 ; auc = 0.9715704316506274 ; cv_num = 2\n",
      "num_trees = 849 ; auc = 0.9715442062018121 ; cv_num = 2\n",
      "num_trees = 850 ; auc = 0.9715272103100906 ; cv_num = 2\n",
      "num_trees = 851 ; auc = 0.9715167426416795 ; cv_num = 2\n",
      "num_trees = 852 ; auc = 0.9715161798638079 ; cv_num = 2\n",
      "num_trees = 853 ; auc = 0.9715081884180314 ; cv_num = 2\n",
      "num_trees = 854 ; auc = 0.9714996341943836 ; cv_num = 2\n",
      "num_trees = 855 ; auc = 0.9714988463053633 ; cv_num = 2\n",
      "num_trees = 856 ; auc = 0.9714896167482694 ; cv_num = 2\n",
      "num_trees = 857 ; auc = 0.9714711576340818 ; cv_num = 2\n",
      "num_trees = 858 ; auc = 0.9714613652991164 ; cv_num = 2\n",
      "num_trees = 859 ; auc = 0.9714507850751308 ; cv_num = 2\n",
      "num_trees = 860 ; auc = 0.9714351398503012 ; cv_num = 2\n",
      "num_trees = 861 ; auc = 0.9714962575271541 ; cv_num = 2\n",
      "num_trees = 862 ; auc = 0.9714847768585739 ; cv_num = 2\n",
      "num_trees = 863 ; auc = 0.9714766728572234 ; cv_num = 2\n",
      "num_trees = 864 ; auc = 0.9714691316337442 ; cv_num = 2\n",
      "num_trees = 865 ; auc = 0.971463728966177 ; cv_num = 2\n",
      "num_trees = 866 ; auc = 0.971446170296584 ; cv_num = 2\n",
      "num_trees = 867 ; auc = 0.9714613652991164 ; cv_num = 2\n",
      "num_trees = 868 ; auc = 0.9714524734087455 ; cv_num = 2\n",
      "num_trees = 869 ; auc = 0.9714444819629692 ; cv_num = 2\n",
      "num_trees = 870 ; auc = 0.9714343519612809 ; cv_num = 2\n",
      "num_trees = 871 ; auc = 0.9714902920817154 ; cv_num = 2\n",
      "num_trees = 872 ; auc = 0.9714768979683719 ; cv_num = 2\n",
      "num_trees = 873 ; auc = 0.9718368506950308 ; cv_num = 2\n",
      "num_trees = 874 ; auc = 0.9718236816928358 ; cv_num = 2\n",
      "num_trees = 875 ; auc = 0.9718137768022961 ; cv_num = 2\n",
      "num_trees = 876 ; auc = 0.9718064606899657 ; cv_num = 2\n",
      "num_trees = 877 ; auc = 0.9718279588046597 ; cv_num = 2\n",
      "num_trees = 878 ; auc = 0.9718232314705387 ; cv_num = 2\n",
      "num_trees = 879 ; auc = 0.9718104001350666 ; cv_num = 2\n",
      "num_trees = 880 ; auc = 0.9718039844673307 ; cv_num = 2\n",
      "num_trees = 881 ; auc = 0.9718284090269569 ; cv_num = 2\n",
      "num_trees = 882 ; auc = 0.9718141144690192 ; cv_num = 2\n",
      "num_trees = 883 ; auc = 0.9718500196972255 ; cv_num = 2\n",
      "num_trees = 884 ; auc = 0.9718400022511114 ; cv_num = 2\n",
      "num_trees = 885 ; auc = 0.9718481062524622 ; cv_num = 2\n",
      "num_trees = 886 ; auc = 0.9718362879171589 ; cv_num = 2\n",
      "num_trees = 887 ; auc = 0.9718272834712138 ; cv_num = 2\n",
      "num_trees = 888 ; auc = 0.9718214305813496 ; cv_num = 2\n",
      "num_trees = 889 ; auc = 0.9718055602453712 ; cv_num = 2\n",
      "num_trees = 890 ; auc = 0.9717974562440205 ; cv_num = 2\n",
      "num_trees = 891 ; auc = 0.9717867634644605 ; cv_num = 2\n",
      "num_trees = 892 ; auc = 0.9717657155720636 ; cv_num = 2\n",
      "num_trees = 893 ; auc = 0.9717578366818617 ; cv_num = 2\n",
      "num_trees = 894 ; auc = 0.9717534470144633 ; cv_num = 2\n",
      "num_trees = 895 ; auc = 0.9717322865664921 ; cv_num = 2\n",
      "num_trees = 896 ; auc = 0.9717233946761212 ; cv_num = 2\n",
      "num_trees = 897 ; auc = 0.9717092126737576 ; cv_num = 2\n",
      "num_trees = 898 ; auc = 0.9717015588947041 ; cv_num = 2\n",
      "num_trees = 899 ; auc = 0.9717012212279814 ; cv_num = 2\n",
      "Best num_trees: 801\n",
      "Best auc corresponding to Best num_trees : 0.9764504214483779\n"
     ]
    }
   ],
   "source": [
    "initial_trees = 801\n",
    "num_trees = 899\n",
    "tree_increment = 1\n",
    "trees = range(initial_trees, num_trees+1, tree_increment)\n",
    "auc = np.zeros((len(trees), num_cv_splits))\n",
    "cv_num = 0\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    clf = ensemble.RandomForestClassifier(criterion='entropy', min_samples_leaf=30, warm_start=True, n_jobs=-1,\n",
    "                                          random_state=0)\n",
    "    for tree_id, tree in enumerate(trees):\n",
    "        clf.set_params(n_estimators=tree)\n",
    "        clf.fit(X_train_cv, y_train_cv)\n",
    "        auc[tree_id, cv_num] = metrics.roc_auc_score(y_true = y_test_cv, y_score = clf.predict_proba(X_test_cv)[:,1])\n",
    "        print('num_trees =', tree, '; auc =', auc[tree_id, cv_num], '; cv_num =', cv_num)\n",
    "    cv_num += 1\n",
    "mean_auc = np.mean(auc, axis=1)\n",
    "print('Best num_trees:', trees[np.argmax(mean_auc)])\n",
    "print('Best auc corresponding to Best num_trees :', mean_auc[np.argmax(mean_auc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b8e56b3337af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# XGBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "num_depth = [3, 4]\n",
    "learning_rate = [0.1, 0.2, 0.3]\n",
    "initial_trees = 1126\n",
    "num_trees = 500\n",
    "tree_increment = 1\n",
    "trees = range(initial_trees, num_trees+1, tree_increment)\n",
    "auc = np.zeros((len(trees)*len(num_depth)*len(learning_rate), num_cv_splits))\n",
    "cv_num = 0\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    for lr_id, lr in enumerate(learning_rate):\n",
    "        for depth_id, depth in enumerate(num_depth):\n",
    "            clf = XGBClassifier(learning_rate=lr, max_depth=depth, min_child_weight=30, n_estimators=initial_trees,\n",
    "                                n_jobs=56)\n",
    "            clf.fit(X_train_cv, y_train_cv)\n",
    "            clf.save_model('lr_'+str(lr)+'_depth_'+str(depth)+'_tree_'+str(initial_trees)+'_cv_num_'+str(cv_num)+\\\n",
    "                           '.model')\n",
    "            auc_id = lr_id*len(num_depth)*len(trees)+depth_id*len(trees)\n",
    "            auc[auc_id, cv_num] = metrics.roc_auc_score(\n",
    "                y_true = y_test_cv, y_score = clf.predict_proba(X_test_cv)[:,1])\n",
    "            print('learning rate =', lr, '; depth =', depth, '; num_trees = ', initial_trees, '; auc =', auc[auc_id,\n",
    "                    cv_num], '; cv_num =', cv_num)\n",
    "            for tree_id,tree in enumerate(trees[1:]):\n",
    "                clf = XGBClassifier(learning_rate=lr, max_depth=depth, min_child_weight=30,\n",
    "                                    n_estimators=tree_increment, n_jobs=56)\n",
    "                clf.fit(X_train_cv, y_train_cv, xgb_model=(\n",
    "                    'lr_'+str(lr)+'_depth_'+str(depth)+'_tree_'+str(trees[tree_id])+'_cv_num_'+str(cv_num)+'.model'))\n",
    "                clf.save_model('lr_'+str(lr)+'_depth_'+str(depth)+'_tree_'+str(tree)+'_cv_num_'+str(cv_num)+'.model')\n",
    "                auc_id = lr_id*len(num_depth)*len(trees)+depth_id*len(trees)+tree_id+1\n",
    "                auc[auc_id, cv_num] = metrics.roc_auc_score(\n",
    "                    y_true = y_test_cv, y_score = clf.predict_proba(X_test_cv)[:,1])\n",
    "                print('learning rate =', lr, '; depth =', depth, '; num_trees =', tree, '; auc =', auc[auc_id,\n",
    "                        cv_num], '; cv_num =', cv_num)\n",
    "    cv_num += 1\n",
    "mean_auc = np.mean(auc, axis=1)\n",
    "lr_id = np.argmax(mean_auc)//(len(num_depth)*len(trees))\n",
    "depth_id = (np.argmax(mean_auc) - lr_id*len(num_depth)*len(trees))//len(trees)\n",
    "tree_id = (np.argmax(mean_auc) - lr_id*len(num_depth)*len(trees))%len(trees)\n",
    "print('Best Learning Rate:', learning_rate[lr_id])\n",
    "print('Best Depth:', num_depth[depth_id])\n",
    "print('Best Trees:', trees[tree_id])\n",
    "print('Best auc corresponding to Best Learning Rate, Depth & Trees :', mean_auc[np.argmax(mean_auc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly explore other algorithms by building models like:\n",
    "- KNN\n",
    "- SVM\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proceed with the model which shows the best result \n",
    "- Apply the best hyperparameter on the model\n",
    "- Predict on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(--> #print the evaluation score on the X_test by choosing the best evaluation metric)? (<ipython-input-19-03f3db1ef6b7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-03f3db1ef6b7>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print --> #print the evaluation score on the X_test by choosing the best evaluation metric\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(--> #print the evaluation score on the X_test by choosing the best evaluation metric)?\n"
     ]
    }
   ],
   "source": [
    "clf = ___  #initialise the model with optimum hyperparameters\n",
    "clf.fit(X_train, y_train)\n",
    "print --> #print the evaluation score on the X_test by choosing the best evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the important features of the best model to understand the dataset\n",
    "- This will not give much explanation on the already transformed dataset\n",
    "- But it will help us in understanding if the dataset is not PCA transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in clf.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
    "\n",
    "# Variable on Index-16 and Index-13 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building with balancing Classes\n",
    "\n",
    "##### Perform class balancing with :\n",
    "- Random Oversampling\n",
    "- SMOTE\n",
    "- ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Build different models on the balanced dataset and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model #import the package\n",
    "\n",
    "num_C = ______  #--> list of values\n",
    "cv_num =   #--> list of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perfom cross validation on the X_train & y_train to create:\n",
    "- X_train_cv\n",
    "- X_test_cv \n",
    "- y_train_cv\n",
    "- y_test_cv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn import over_sampling #- import the packages\n",
    "\n",
    "#perform cross validation & then balance classes on X_train_cv & y_train_cv using Random Oversampling\n",
    "\n",
    "#perform hyperparameter tuning\n",
    "\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "\n",
    "#print the optimum value of hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly explore other algorithms on balanced dataset by building models like:\n",
    "- KNN\n",
    "- SVM\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the class distribution after applying SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "sm = over_sampling.SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from SMOTE are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from SMOTE, we do\n",
    "X_train_smote_1 = X_train_smote[X_train.shape[0]:]\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_smote_1[:X_train_1.shape[0], 0], X_train_smote_1[:X_train_1.shape[0], 1],\n",
    "            label='Artificial SMOTE Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross validation & then balance classes on X_train_cv & y_train_cv using SMOTE\n",
    "\n",
    "#perform hyperparameter tuning\n",
    "\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "\n",
    "#print the optimum value of hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build models on other algorithms to see the better performing on SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the class distribution after applying ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from imblearn import over_sampling\n",
    "\n",
    "ada = over_sampling.ADASYN(random_state=0)\n",
    "X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from ADASYN are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from ADASYN, we do\n",
    "X_train_adasyn_1 = X_train_adasyn[X_train.shape[0]:]\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_adasyn_1[:X_train_1.shape[0], 0], X_train_adasyn_1[:X_train_1.shape[0], 1],\n",
    "            label='Artificial ADASYN Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross validation & then balance classes on X_train_cv & y_train_cv using ADASYN\n",
    "\n",
    "#perform hyperparameter tuning\n",
    "\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "\n",
    "#print the optimum value of hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build models on other algorithms to see the better performing on ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the oversampling method which shows the best result on a model\n",
    "- Apply the best hyperparameter on the model\n",
    "- Predict on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the best oversampling method on X_train & y_train\n",
    "\n",
    "clf = ___  #initialise the model with optimum hyperparameters\n",
    "clf.fit( ) # fit on the balanced dataset\n",
    "print() --> #print the evaluation score on the X_test by choosing the best evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the important features of the best model to understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in clf.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
    "\n",
    "# Variable on Index-13 and Index-9 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Print the FPR,TPR & select the best threshold from the roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train auc =', metrics.roc_auc_score(_________)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(_________)\n",
    "threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "print(threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
